{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c8387b4",
   "metadata": {},
   "source": [
    "<p style='text-align: center'>\n",
    "    <img src='images/cesi.png' width=\"20%\">\n",
    "    <div style='text-align: center'>Rima Benrejeb, Thomas Mattone, Bastien Reynaud, Badreddine Ferragh</div>\n",
    "</p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c76a0b3",
   "metadata": {},
   "source": [
    "# Leyenda - Image classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b32f8b",
   "metadata": {
    "papermill": {
     "duration": 0.011808,
     "end_time": "2022-09-05T05:05:38.744112",
     "exception": false,
     "start_time": "2022-09-05T05:05:38.732304",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **Table Of Contents**\n",
    "> 1. [Objective](#1)\n",
    "> 2. [Data](#2)\n",
    "> 3. [Notebook imports](#3)\n",
    "> 4. [Importing data](#4)\n",
    "> 5. [Hyper-parameters](#5)\n",
    "> 6. [Deep Neural Networks](#6)\n",
    "> 7. [Convolutional Neural Networks](#7)\n",
    "> 8. [Improving models](#8)\n",
    "> 9. [Improving training](#9)\n",
    "> 10. [Transfer Learning](#10)\n",
    "> 11. [Results](#11)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f7ff07",
   "metadata": {},
   "source": [
    "## Objective <a class=\"anchor\" id=\"1\"></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5022e13e",
   "metadata": {},
   "source": [
    "This notebook presents our implementation of an image classifier using Deep Learning.\n",
    "\n",
    "It gathers our design process steps and idea on how to create the most accurate and efficient Neural Network for this task.\n",
    "\n",
    "Please note that I you run this notebook code on your own, **you may encounter different accuracy results** than the ones we obtained. <br>\n",
    "This is due on the way the `model.evaluate()` function works in TensorFlow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56063a0",
   "metadata": {},
   "source": [
    "## Data <a class=\"anchor\" id=\"2\"></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46662a55",
   "metadata": {},
   "source": [
    "The dataset is composed of 41.406 images splits into 5 differents classes: painting (10.000), photo (10.000), schematic (10.000), sketch (1406) and text (10.000). <br>\n",
    "The images are either in .jpeg or .png format and come in variety of dimensions.\n",
    "\n",
    "The make this notebook more easy to read, the original dataset has been pre-splits into a training (80%), validation (10%) and testing (10%) set, and then uploaded into a [Kaggle dataset](https://www.kaggle.com/datasets/eccsx20/image-type-classification). <br>\n",
    "We also remove all non-processable images, due to invalid format or wrong color profile."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25efed4",
   "metadata": {
    "papermill": {
     "duration": 0.009516,
     "end_time": "2022-09-05T05:05:38.764094",
     "exception": false,
     "start_time": "2022-09-05T05:05:38.754578",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Notebook imports <a class=\"anchor\" id=\"3\"></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a3465c-8070-414d-93ca-4c7d3ac3ea64",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-04T10:31:53.051007Z",
     "iopub.status.busy": "2022-10-04T10:31:53.050849Z",
     "iopub.status.idle": "2022-10-04T10:31:53.058979Z",
     "shell.execute_reply": "2022-10-04T10:31:53.058360Z",
     "shell.execute_reply.started": "2022-10-04T10:31:53.050990Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext watermark\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# File manipulation\n",
    "import os\n",
    "import pathlib\n",
    "import shutil\n",
    "import wget\n",
    "import zipfile\n",
    "\n",
    "# Data manipulation\n",
    "import numpy as np\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Dropout, Input, Flatten, MaxPool2D\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import SparseCategoricalAccuracy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow_hub as tf_hub\n",
    "\n",
    "tf.random.set_seed(1234)\n",
    "\n",
    "# Image manipulation\n",
    "import imghdr\n",
    "from PIL import ImageFile\n",
    "\n",
    "# Options for PIL\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import visualkeras\n",
    "\n",
    "# Options for seaborn\n",
    "sns.set_style('darkgrid')\n",
    "%matplotlib inline\n",
    "\n",
    "# Utils\n",
    "import leyenda_utils as lu\n",
    "\n",
    "%watermark -p watermark,wget,numpy,sklearn,tensorflow,tensorflow_hub,PIL,matplotlib,seaborn,visualkeras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e5a4aa",
   "metadata": {
    "papermill": {
     "duration": 0.009795,
     "end_time": "2022-09-05T05:05:50.884801",
     "exception": false,
     "start_time": "2022-09-05T05:05:50.875006",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Importing data <a class=\"anchor\" id=\"4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991533ec",
   "metadata": {},
   "source": [
    "We import the data from the [Kaggle dataset](https://www.kaggle.com/datasets/eccsx20/image-type-classification).\n",
    "\n",
    "Please note that if you want to download the data using the following code, you will need to get your own download link. <br>\n",
    "To do so, go on the dataset page and click on the 'download' at the top-right corner. Then quickly stop the dowload in your browser and right-click to retrieve the download link."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6ac2c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-04T10:10:35.632403Z",
     "iopub.status.busy": "2022-10-04T10:10:35.632246Z",
     "iopub.status.idle": "2022-10-04T10:10:35.636114Z",
     "shell.execute_reply": "2022-10-04T10:10:35.635538Z",
     "shell.execute_reply.started": "2022-10-04T10:10:35.632386Z"
    },
    "papermill": {
     "duration": 0.033485,
     "end_time": "2022-09-05T05:05:50.928398",
     "exception": false,
     "start_time": "2022-09-05T05:05:50.894913",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_URL = None # YOUR DOWLOAD LINK HERE\n",
    "DATA_PATH = 'data/image_type'\n",
    "\n",
    "if not os.path.isdir(DATA_PATH):\n",
    "    wget.download(DATA_URL)\n",
    "\n",
    "    with zipfile.ZipFile('archive.zip') as zf:\n",
    "        zf.extractall('data')\n",
    "\n",
    "    os.remove('archive.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb5be08",
   "metadata": {},
   "source": [
    "Even if the dataset is already clean, we run a quick verification of all the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e85fef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-04T10:10:37.632746Z",
     "iopub.status.busy": "2022-10-04T10:10:37.632588Z",
     "iopub.status.idle": "2022-10-04T10:10:37.636800Z",
     "shell.execute_reply": "2022-10-04T10:10:37.636404Z",
     "shell.execute_reply.started": "2022-10-04T10:10:37.632729Z"
    },
    "papermill": {
     "duration": 0.024834,
     "end_time": "2022-09-05T05:05:50.963379",
     "exception": false,
     "start_time": "2022-09-05T05:05:50.938545",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dir = pathlib.Path(os.path.join(DATA_PATH))\n",
    "invalid_images = []\n",
    "\n",
    "for file in list(data_dir.glob('*/*.*')):\n",
    "    if imghdr.what(file) not in ['jpeg', 'png']:\n",
    "        invalid_images.append(file)\n",
    "        \n",
    "print(f'{len(invalid_images)} invalids images')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55269192",
   "metadata": {},
   "source": [
    "In the case we encounter no-usable images, we move them into a different directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e9e481-0bc7-4d94-9263-0a874609be6d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-04T10:10:39.785701Z",
     "iopub.status.busy": "2022-10-04T10:10:39.785114Z",
     "iopub.status.idle": "2022-10-04T10:10:39.793214Z",
     "shell.execute_reply": "2022-10-04T10:10:39.792202Z",
     "shell.execute_reply.started": "2022-10-04T10:10:39.785598Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if len(invalid_images) > 0:\n",
    "    if not os.path.isdir('data/invalid'):\n",
    "        os.mkdir('data/invalid')\n",
    "\n",
    "    for image in invalid_images:\n",
    "        shutil.move(image, 'data/invalid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6462c13",
   "metadata": {},
   "source": [
    "Then, we load the images into their respective training, valdation and testing set.\n",
    "\n",
    "In the same time, we normalize all the image into the `IMG_H` by  `IMG_W` size, and map all pixel values between 0 and 1. <br>\n",
    "The image labels are also converted into integers to make model training easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d74eb6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-04T10:10:40.750827Z",
     "iopub.status.busy": "2022-10-04T10:10:40.750572Z",
     "iopub.status.idle": "2022-10-04T10:10:41.436688Z",
     "shell.execute_reply": "2022-10-04T10:10:41.436127Z",
     "shell.execute_reply.started": "2022-10-04T10:10:40.750800Z"
    },
    "papermill": {
     "duration": 0.242613,
     "end_time": "2022-09-05T05:05:52.061594",
     "exception": false,
     "start_time": "2022-09-05T05:05:51.818981",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "IMG_H, IMG_W = 224, 224\n",
    "\n",
    "data_gen = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "train_data = data_gen.flow_from_directory(os.path.join(DATA_PATH, 'train'), \n",
    "                                          target_size=(IMG_H, IMG_W), \n",
    "                                          batch_size=BATCH_SIZE,\n",
    "                                          class_mode='binary',\n",
    "                                          seed=42)\n",
    "\n",
    "val_data = data_gen.flow_from_directory(os.path.join(DATA_PATH, 'val'), \n",
    "                                        target_size=(IMG_H, IMG_W), \n",
    "                                        batch_size=BATCH_SIZE,\n",
    "                                        class_mode='binary',\n",
    "                                        seed=42)\n",
    "\n",
    "test_data = data_gen.flow_from_directory(os.path.join(DATA_PATH, 'test'), \n",
    "                                         target_size=(IMG_H, IMG_W), \n",
    "                                         batch_size=BATCH_SIZE,\n",
    "                                         class_mode='binary',\n",
    "                                         seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25077255",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-04T10:10:42.312035Z",
     "iopub.status.busy": "2022-10-04T10:10:42.311796Z",
     "iopub.status.idle": "2022-10-04T10:10:42.316586Z",
     "shell.execute_reply": "2022-10-04T10:10:42.316012Z",
     "shell.execute_reply.started": "2022-10-04T10:10:42.312009Z"
    },
    "papermill": {
     "duration": 0.469366,
     "end_time": "2022-09-05T05:05:52.541970",
     "exception": false,
     "start_time": "2022-09-05T05:05:52.072604",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(train_data.class_indices)\n",
    "print(val_data.class_indices)\n",
    "print(test_data.class_indices)\n",
    "\n",
    "CLASS_NAMES = list(train_data.class_indices.keys())\n",
    "print(CLASS_NAMES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b23bd9",
   "metadata": {
    "papermill": {
     "duration": 0.009522,
     "end_time": "2022-09-05T05:05:51.808952",
     "exception": false,
     "start_time": "2022-09-05T05:05:51.799430",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Visualizing the images <a class=\"anchor\" id=\"3\"></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5e2e86",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-04T09:11:52.154863Z",
     "iopub.status.busy": "2022-10-04T09:11:52.154628Z",
     "iopub.status.idle": "2022-10-04T09:11:52.162116Z",
     "shell.execute_reply": "2022-10-04T09:11:52.161171Z",
     "shell.execute_reply.started": "2022-10-04T09:11:52.154837Z"
    },
    "papermill": {
     "duration": 0.029344,
     "end_time": "2022-09-05T05:05:52.588133",
     "exception": false,
     "start_time": "2022-09-05T05:05:52.558789",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_random_images():\n",
    "    \"\"\"\n",
    "    Plots 20 Random Images from the dataset\n",
    "    \"\"\"\n",
    "    \n",
    "    images, labels = train_data.next()\n",
    "    labels = labels.astype('int32')\n",
    "    i = 1\n",
    "\n",
    "    plt.figure(figsize = (10, 10))\n",
    "   \n",
    "    for image, label in zip(images, labels):\n",
    "        plt.subplot(4, 5, i)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        plt.title('\\n\\n'+list(train_data.class_indices.keys())[label])\n",
    "        plt.imshow(image)\n",
    "\n",
    "        i += 1\n",
    "        if i == 21:\n",
    "            break\n",
    "    \n",
    "    plt.tight_layout()       \n",
    "    plt.suptitle(\"Randomly picked images from training set\", fontsize=16, fontweight=\"bold\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89dfd15a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-04T09:11:53.176819Z",
     "iopub.status.busy": "2022-10-04T09:11:53.176516Z",
     "iopub.status.idle": "2022-10-04T09:11:54.477222Z",
     "shell.execute_reply": "2022-10-04T09:11:54.476677Z",
     "shell.execute_reply.started": "2022-10-04T09:11:53.176782Z"
    },
    "papermill": {
     "duration": 3.316769,
     "end_time": "2022-09-05T05:05:55.916049",
     "exception": false,
     "start_time": "2022-09-05T05:05:52.599280",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_random_images()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d97a656",
   "metadata": {},
   "source": [
    "## Hyper-parameters <a class=\"anchor\" id=\"5\"></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33266384",
   "metadata": {},
   "source": [
    "In order to be able to compare the model troughout the notebook, we chose to training them using the configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40bb953",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCH = 15\n",
    "LOSS = SparseCategoricalCrossentropy()\n",
    "OPTIMIZER = Adam(1e-3)\n",
    "METRICS = [SparseCategoricalAccuracy()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac0318b",
   "metadata": {
    "papermill": {
     "duration": 0.01395,
     "end_time": "2022-09-05T05:05:55.944564",
     "exception": false,
     "start_time": "2022-09-05T05:05:55.930614",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Deep Neural Network <a class=\"anchor\" id=\"6\"></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644641a3",
   "metadata": {},
   "source": [
    "### Baseline model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af05a8c2",
   "metadata": {},
   "source": [
    "We began with a dummy `dnn_1`, to be able to visualize how behave a poorly designed network.\n",
    "\n",
    "It is only composed of a `Dense` ouput layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0afe25",
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_1 = Sequential([\n",
    "    Flatten(input_shape=(IMG_H, IMG_W, 3)),\n",
    "    Dense(units=len(CLASS_NAMES), activation='softmax')\n",
    "], name='dnn_1')\n",
    "\n",
    "dnn_1.compile(loss=LOSS,\n",
    "              optimizer=OPTIMIZER,\n",
    "              metrics=METRICS)\n",
    "\n",
    "visualkeras.layered_view(dnn_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d591e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "if lu.is_model_already_trained(dnn_1):\n",
    "    lu.load_model_training(dnn_1)\n",
    "else:\n",
    "    dnn_1.fit(train_data,\n",
    "              epochs= NUM_EPOCH,\n",
    "              steps_per_epoch = len(train_data),\n",
    "              validation_data = val_data,\n",
    "              validation_steps = len(val_data))\n",
    "            \n",
    "    lu.save_model_training(dnn_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86edc345",
   "metadata": {},
   "source": [
    "Without any surprise, the `loss` had trouble to deacreasing and the `accuracy` increase really slowly.\n",
    "\n",
    "It is even worse for the `val_loss` and `val_accuracy` which are complety choatic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fce51e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lu.plot_model_history(dnn_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ab6d7c",
   "metadata": {},
   "source": [
    "`dnn_1` barely reach the 60% of accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee190415",
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_1.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fa7207",
   "metadata": {},
   "source": [
    "### Adding hidden layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9da8b5",
   "metadata": {},
   "source": [
    "To start building a real network, we added multiple hidden layers.\n",
    "\n",
    "`dnn_2` is made of 4 `Dense` hidden layers of respectively 1024, 512, 256, and 128 units, actived with the ReLU function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ab6cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_2 = Sequential([\n",
    "    Flatten(input_shape=(IMG_H, IMG_W, 3)),\n",
    "    Dense(units=1024, activation='relu'),\n",
    "    Dense(units=512, activation='relu'),\n",
    "    Dense(units=256, activation='relu'),\n",
    "    Dense(units=128, activation='relu'),\n",
    "    Dense(units=len(CLASS_NAMES), activation='softmax')\n",
    "], name='dnn_2')\n",
    "\n",
    "dnn_2.compile(loss=LOSS,\n",
    "              optimizer=OPTIMIZER,\n",
    "              metrics=METRICS)\n",
    "\n",
    "visualkeras.layered_view(dnn_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2b461c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if lu.is_model_already_trained(dnn_2):\n",
    "    lu.load_model_training(dnn_2)\n",
    "else:\n",
    "    dnn_2.fit(train_data,\n",
    "              epochs= NUM_EPOCH,\n",
    "              steps_per_epoch = len(train_data),\n",
    "              validation_data = val_data,\n",
    "              validation_steps = len(val_data))\n",
    "            \n",
    "    lu.save_model_training(dnn_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de809522",
   "metadata": {},
   "source": [
    "It's already doing much better.\n",
    "\n",
    "The `loss` drops down quickly, and the `accuracy` is increasing. <br>\n",
    "However, the `val_loss` and `val_accuracy` do not change a lot over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410c3006",
   "metadata": {},
   "outputs": [],
   "source": [
    "lu.plot_model_history(dnn_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654bf205",
   "metadata": {},
   "source": [
    "Compare to `dnn_1`, `dnn_2` is more accurate but not enough to provide an efficient solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d471db",
   "metadata": {},
   "outputs": [],
   "source": [
    "lu.load_model_training(dnn_1)\n",
    "\n",
    "lu.plot_models_history([dnn_1, dnn_2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d64415",
   "metadata": {},
   "source": [
    "`dnn_2` only offers an accuracy of 75%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6753df3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_2.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f51a237",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-03T13:56:26.895649Z",
     "iopub.status.busy": "2022-09-03T13:56:26.895264Z",
     "iopub.status.idle": "2022-09-03T13:56:26.900645Z",
     "shell.execute_reply": "2022-09-03T13:56:26.899279Z",
     "shell.execute_reply.started": "2022-09-03T13:56:26.895618Z"
    },
    "papermill": {
     "duration": 0.013261,
     "end_time": "2022-09-05T05:05:55.971949",
     "exception": false,
     "start_time": "2022-09-05T05:05:55.958688",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Convolutional Neural Network <a class=\"anchor\" id=\"7\"></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0801af5a",
   "metadata": {},
   "source": [
    "The reason of the bad performance of `dnn_1` and `dnn_2` for image classification is that Deep Neural Networks are not designed for that kind of task.\n",
    "\n",
    "Convolutional Neural Networks were invented to provide a more meaningful way to analyse images in order to classifier them. <br>\n",
    "Instead of processing all the pixels of an image at once, it goes through pixels groups using a kernel in order to detect image specicities like contours, edges or color changes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c4d05d",
   "metadata": {},
   "source": [
    "<img src='images/convolution.gif'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19733074",
   "metadata": {},
   "source": [
    "### Baseline model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1148e46a",
   "metadata": {},
   "source": [
    "Let's create a first simple one to see how more efficient it is regarding `dnn_2`.\n",
    "\n",
    "`cnn_1` is composed of 2 `Conv2D` layers with 23 filter and a kernel size of 2, actived using the ReLU function. <br>\n",
    "To classify, a simple `Dense` output layer is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0732c507",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2022-10-04T11:16:29.708170Z",
     "iopub.status.busy": "2022-10-04T11:16:29.707951Z",
     "iopub.status.idle": "2022-10-04T11:28:42.244042Z",
     "shell.execute_reply": "2022-10-04T11:28:42.243535Z",
     "shell.execute_reply.started": "2022-10-04T11:16:29.708146Z"
    },
    "papermill": {
     "duration": 102.103944,
     "end_time": "2022-09-05T05:07:38.089720",
     "exception": false,
     "start_time": "2022-09-05T05:05:55.985776",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cnn_1 = Sequential([\n",
    "    Input(shape=(IMG_H, IMG_W, 3)), \n",
    "    Conv2D(filters=32, kernel_size=2, activation='relu'),\n",
    "    Conv2D(filters=32, kernel_size=2, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(len(CLASS_NAMES), activation='softmax')\n",
    "], name='cnn_1')\n",
    "\n",
    "cnn_1.compile(loss=LOSS,\n",
    "              optimizer=OPTIMIZER,\n",
    "              metrics=METRICS)\n",
    "\n",
    "visualkeras.layered_view(cnn_1, scale_xy=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c080fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if lu.is_model_already_trained(cnn_1):\n",
    "    lu.load_model_training(cnn_1)\n",
    "else:\n",
    "    cnn_1.fit(train_data,\n",
    "              epochs= NUM_EPOCH,\n",
    "              steps_per_epoch = len(train_data),\n",
    "              validation_data = val_data,\n",
    "              validation_steps = len(val_data))\n",
    "            \n",
    "    lu.save_model_training(cnn_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcdd1205",
   "metadata": {},
   "source": [
    "We are on the way as `cnn_1`'s `loss` is almost 0 and its `accuracy` tends toward 100%.\n",
    "\n",
    "However, a bigger problme is now showing up: the overfitting.\n",
    "\n",
    "From this point, our biggest challenge is going to make `val_loss` decrease while increasing `val_accuracy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043ada3f-9b87-41b6-86d5-2cacd852889f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-04T11:45:14.679473Z",
     "iopub.status.busy": "2022-10-04T11:45:14.678972Z",
     "iopub.status.idle": "2022-10-04T11:45:15.039903Z",
     "shell.execute_reply": "2022-10-04T11:45:15.039474Z",
     "shell.execute_reply.started": "2022-10-04T11:45:14.679413Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lu.plot_model_history(cnn_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc0fb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "lu.load_model_training(dnn_2)\n",
    "\n",
    "lu.plot_models_history([dnn_2, cnn_1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0d23d3",
   "metadata": {},
   "source": [
    "This first iteration gives an accuracy around 80%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6f0d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_1.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70349cfa",
   "metadata": {},
   "source": [
    "### Adding max-pooling layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a935bc8",
   "metadata": {
    "papermill": {
     "duration": 0.033076,
     "end_time": "2022-09-05T05:07:39.349640",
     "exception": false,
     "start_time": "2022-09-05T05:07:39.316564",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "To improve our model, we can add `MaxPool2D` layers after each convolutional layer.\n",
    "\n",
    "Max-pooling allowes to encode an image into smaller dimension by only keeping the maximum pixel value during the kernel iteration. <br>\n",
    "It has many advantages such as only keeping relevant image information and reducing the duraiton of the training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d864eaa",
   "metadata": {},
   "source": [
    "<img src='images/maxpooling.gif'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872165b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-04T10:33:01.712543Z",
     "iopub.status.busy": "2022-10-04T10:33:01.712362Z",
     "iopub.status.idle": "2022-10-04T10:47:22.346443Z",
     "shell.execute_reply": "2022-10-04T10:47:22.346030Z",
     "shell.execute_reply.started": "2022-10-04T10:33:01.712523Z"
    },
    "papermill": {
     "duration": 82.66477,
     "end_time": "2022-09-05T05:09:02.064755",
     "exception": false,
     "start_time": "2022-09-05T05:07:39.399985",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cnn_2 = Sequential([\n",
    "    Input(shape = (224, 224, 3)),   \n",
    "    Conv2D(filters = 32, kernel_size = 2, padding = 'valid', activation = 'relu'), \n",
    "    MaxPool2D(pool_size = 2), # It will reduce the number of features by half\n",
    "    Conv2D(filters = 32, kernel_size =2, padding = 'valid', activation = 'relu'),\n",
    "    MaxPool2D(pool_size = 2),\n",
    "    Flatten(),\n",
    "    Dense(len(CLASS_NAMES), activation = 'softmax')  \n",
    "], name='cnn_2')\n",
    "\n",
    "cnn_2.compile(loss = LOSS,\n",
    "              optimizer = OPTIMIZER,\n",
    "              metrics = METRICS)\n",
    "\n",
    "visualkeras.layered_view(cnn_2, scale_xy=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db092f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if lu.is_model_already_trained(cnn_2):\n",
    "    lu.load_model_training(cnn_2)\n",
    "else:               \n",
    "    cnn_2.fit(train_data,\n",
    "            epochs= NUM_EPOCH,\n",
    "            steps_per_epoch = len(train_data),\n",
    "            validation_data = val_data,\n",
    "            validation_steps = len(val_data))\n",
    "            \n",
    "    lu.save_model_training(cnn_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f8f825",
   "metadata": {},
   "source": [
    "Despite the max-pooling, `cnn_2` is still overfitting but this time much slower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1929af-4b69-438c-b2f5-d1485f957c25",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-04T11:40:04.565823Z",
     "iopub.status.busy": "2022-10-04T11:40:04.565504Z",
     "iopub.status.idle": "2022-10-04T11:40:05.212365Z",
     "shell.execute_reply": "2022-10-04T11:40:05.211792Z",
     "shell.execute_reply.started": "2022-10-04T11:40:04.565787Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lu.plot_model_history(cnn_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34a16e3",
   "metadata": {},
   "source": [
    "It is still a good improvement compare to `cnn_1`, especially regarding the `val_accuracy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e2a944",
   "metadata": {},
   "outputs": [],
   "source": [
    "lu.load_model_training(cnn_1)\n",
    "\n",
    "lu.plot_models_history([cnn_1, cnn_2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0926ea3e",
   "metadata": {
    "papermill": {
     "duration": 0.074223,
     "end_time": "2022-09-05T05:12:25.407522",
     "exception": false,
     "start_time": "2022-09-05T05:12:25.333299",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "`cnn_2` does sligthly better than it predecessor, reaching 84% of accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73946187",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f73328e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_2.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5551f5b1",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4a28f0",
   "metadata": {},
   "source": [
    "To improve improve our solution even, we can create an encoder.\n",
    "\n",
    "To do so, we can add more `Conv2D` layers with an increasing number of filters adn a bigger kernel size.\n",
    "\n",
    "To also improve the classification at the end of the convolution, we add a `Dense` layer of 512 units, precede by a `Droupout` of 50%.\n",
    "\n",
    "Droupout is one of many techinique of weight regularization and helps reducing overfitting by ignore each epochs a certain percentage of neurons connection between two layers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea621121",
   "metadata": {
    "_kg_hide-output": true,
    "papermill": {
     "duration": 333.397573,
     "end_time": "2022-09-05T05:17:58.877976",
     "exception": false,
     "start_time": "2022-09-05T05:12:25.480403",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cnn_3 = Sequential([\n",
    "    Input(shape=(IMG_H, IMG_W, 3)),\n",
    "    Conv2D(filters=16, kernel_size=(3, 3), activation='relu'),\n",
    "    MaxPool2D((2, 2)),\n",
    "    Conv2D(filters=32, kernel_size=(3, 3), activation='relu'),\n",
    "    MaxPool2D((2, 2)),\n",
    "    Conv2D(filters=64, kernel_size=(3, 3), activation='relu'),\n",
    "    MaxPool2D((2, 2)),\n",
    "    Conv2D(filters=128, kernel_size=(3, 3), activation='relu'),\n",
    "    MaxPool2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dropout(0.5),\n",
    "    Dense(units=512, activation='relu'),\n",
    "    Dense(units=len(CLASS_NAMES), activation='softmax')\n",
    "], name='cnn_3')\n",
    "\n",
    "cnn_3.compile(loss = LOSS,\n",
    "              optimizer = OPTIMIZER,\n",
    "              metrics = METRICS)\n",
    "\n",
    "visualkeras.layered_view(cnn_3, scale_xy=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef3f082",
   "metadata": {},
   "outputs": [],
   "source": [
    "if lu.is_model_already_trained(cnn_3):\n",
    "    lu.load_model_training(cnn_3)\n",
    "else:               \n",
    "    cnn_3.fit(train_data,\n",
    "            epochs= NUM_EPOCH,\n",
    "            steps_per_epoch = len(train_data),\n",
    "            validation_data = val_data,\n",
    "            validation_steps = len(val_data))\n",
    "            \n",
    "    lu.save_model_training(cnn_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9a5067",
   "metadata": {},
   "source": [
    "With this type of architecture, `cnn_3` is finally starting to behave correctly.\n",
    "\n",
    "Even if not by a lot, `val_loss` decreases and `val_accuracy` increases during the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3121d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "lu.plot_model_history(cnn_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066965c9",
   "metadata": {},
   "source": [
    "In comparision with the previous model, `cnn_3` is much more promising."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b08846c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lu.load_model_training(cnn_1)\n",
    "lu.load_model_training(cnn_2)\n",
    "\n",
    "lu.plot_models_history([cnn_1, cnn_2, cnn_3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40adf63",
   "metadata": {},
   "source": [
    "After its training, `cnn_3` is just over 86% of accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8315f580",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_3.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd8983e",
   "metadata": {},
   "source": [
    "## Improving models <a class=\"anchor\" id=\"8\"></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64416a5",
   "metadata": {},
   "source": [
    "From now on, improving our models mostly relies on trial and error. <br>\n",
    "Indeed, there is no today no existing method to fing the best model architecture for a given problem, and this topic is still an active field of research.\n",
    "\n",
    "There are however some known techniques, call regularization, that can be used to reduce overfitting and improve the validation accuracy during training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28de42de",
   "metadata": {},
   "source": [
    "### Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3ae112",
   "metadata": {},
   "source": [
    "Already used in `cnn_3`, dropout allows each neurons connection between two layers has a certain percentage to be ignored at each epoch.\n",
    "<img scr='images/dropout.gif'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9d8da8-8c38-4898-ad30-4ec7cdb79394",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-08T15:52:24.950229Z",
     "iopub.status.busy": "2022-10-08T15:52:24.950037Z",
     "iopub.status.idle": "2022-10-08T15:52:24.956720Z",
     "shell.execute_reply": "2022-10-08T15:52:24.956145Z",
     "shell.execute_reply.started": "2022-10-08T15:52:24.950176Z"
    },
    "tags": []
   },
   "source": [
    "<img src='images/dropout.gif' width='30%'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c134004",
   "metadata": {},
   "source": [
    "### L1 and L2 regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d578cee",
   "metadata": {},
   "source": [
    "Allows to constrain the weights of a model to be smaller or to shrink some of them to 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bd099f",
   "metadata": {},
   "source": [
    "### Early-stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f132f3a7",
   "metadata": {},
   "source": [
    "Stops the training of a model when a metric such as the loss or the accuracy stop improving.\n",
    "\n",
    "<img src='images/earlystopping.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3037dbe",
   "metadata": {},
   "source": [
    "### Data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9fdfccb",
   "metadata": {},
   "source": [
    "Creates new relevant data from the existing one.\n",
    "\n",
    "In the case of image classes, we can create new images but apply transformation on images from the a dataset such as cropping, ratotions, symmetries, shifting or color modification. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78cc1630",
   "metadata": {},
   "source": [
    "<img src='images/imageaugmentation.jpeg' width='60%'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d9890a",
   "metadata": {},
   "source": [
    "## Improving training <a class=\"anchor\" id=\"9\"></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb8acfd",
   "metadata": {},
   "source": [
    "Random Search is a technique used for tuning hyperparameters in order to find those who suit best our model. <br>\n",
    "In fact, it tests a certain number of combinations that are selected randomly. <br>\n",
    "However, this technique require much ressources. \n",
    "\n",
    "The following code can be used in order to implement this technique:\n",
    "\n",
    "```python\n",
    "from  keras_tuner import RandomSearch\n",
    "random_s= RandomSearch(cnn_3,\n",
    "                       objectives= 'val_accuracy',\n",
    "                       max_trials=15)\n",
    "random_s.seach(train_data,\n",
    "               epochs=5,\n",
    "               validation_data= val_data,\n",
    "               callbacks=[tf.keras.callbacks.EarlyStopping(patiente=1)])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00982f02",
   "metadata": {
    "papermill": {
     "duration": 0.149559,
     "end_time": "2022-09-05T05:18:01.122059",
     "exception": false,
     "start_time": "2022-09-05T05:18:00.972500",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Transfer Learning <a class=\"anchor\" id=\"10\"></a>  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069c96f3",
   "metadata": {},
   "source": [
    "The idea behind Transfer Learning is to take an already existing model that has been trained on a similar task than ours, and then re-train it to fit our needs.\n",
    "\n",
    "This methods is far more efficient compare to the trial-and-error approch because a lot of models has already been designed, trained and documented way better than what we could think of."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e00d6a",
   "metadata": {
    "papermill": {
     "duration": 0.187603,
     "end_time": "2022-09-05T05:22:06.244371",
     "exception": false,
     "start_time": "2022-09-05T05:22:06.056768",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### VGG16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858dc074",
   "metadata": {},
   "source": [
    "VGG16 is a Convolutional Neural Network model proposed by K. Simonyan and A. Zisserman from the University of Oxford in the paper “Very Deep Convolutional Networks for the Large-Scale Image Recognition”.\n",
    "\n",
    "The model achieves 92.7% test accuracy in ImageNet, which is the dataset of over 14 million images belonging to the 1000 classes.\n",
    "\n",
    "Since our goal is similar, it would be interesting to try using Transfer Learning with this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019362e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_vgg = tf.keras.applications.VGG16(input_shape = (IMG_H, IMG_W, 3),\n",
    "                                             include_top = False,\n",
    "                                             weights = 'imagenet')\n",
    "                                             \n",
    "for layer in base_model_vgg.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2b7c6c",
   "metadata": {},
   "source": [
    "Since we only want to keep the weigths of the VGG16 model, we desactivated the training of the convolutional layers.\n",
    "\n",
    "Then to classify our images, we add the same `Dense` and `Dropout` layer configuration as our `cnn_3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61408e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.keras.layers.Flatten()(base_model_vgg.output)\n",
    "x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "x = tf.keras.layers.Dense(len(CLASS_NAMES), activation='softmax')(x)\n",
    "\n",
    "vgg_16 = tf.keras.models.Model(base_model_vgg.input, x) #merge the original VGG-16 layers, with our custom layers.\n",
    "vgg_16._name = 'vgg_16'\n",
    "\n",
    "vgg_16.compile(loss = LOSS,\n",
    "               optimizer = OPTIMIZER,\n",
    "               metrics = METRICS)\n",
    "               \n",
    "visualkeras.layered_view(vgg_16, scale_xy=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14744925",
   "metadata": {},
   "outputs": [],
   "source": [
    "if lu.is_model_already_trained(vgg_16):\n",
    "    lu.load_model_training(vgg_16)\n",
    "else:               \n",
    "    vgg_16.fit(train_data,\n",
    "            epochs= 5,\n",
    "            steps_per_epoch = len(train_data),\n",
    "            validation_data = val_data,\n",
    "            validation_steps = len(val_data))\n",
    "            \n",
    "    lu.save_model_training(vgg_16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6041383b",
   "metadata": {},
   "source": [
    "Even if we reduce the number of epoch to 5 due to a lack of computational power, the re-trained VGG16 complety outperform our `cnn_3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1644f0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lu.plot_model_history(vgg_16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a664e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "lu.load_model_training(cnn_3)\n",
    "\n",
    "lu.plot_models_history([cnn_3, vgg_16])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6697cc09",
   "metadata": {},
   "source": [
    "`vgg_16` gives us an astonishing 94% of accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec90b8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_16.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944f1d2d",
   "metadata": {
    "papermill": {
     "duration": 0.150171,
     "end_time": "2022-09-05T05:18:00.821692",
     "exception": false,
     "start_time": "2022-09-05T05:18:00.671521",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### EfficientNetB7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e288308d",
   "metadata": {},
   "source": [
    "EffecientNetB7 is a Convolutional Neural Network develop by Google AI, which reachs state-of-the-art accuracy on biggest image classification datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7adce76",
   "metadata": {
    "papermill": {
     "duration": 243.394758,
     "end_time": "2022-09-05T05:22:04.666813",
     "exception": false,
     "start_time": "2022-09-05T05:18:01.272055",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_extractor_layer = tf_hub.KerasLayer('https://tfhub.dev/google/efficientnet/b7/feature-vector/1',\n",
    "                                            trainable=False,\n",
    "                                            input_shape=(224, 224, 3))\n",
    "\n",
    "ef_net_b7 = Sequential([\n",
    "    feature_extractor_layer,\n",
    "    Dense(len(CLASS_NAMES), activation='softmax')\n",
    "], name='ef_net_b7')\n",
    "\n",
    "ef_net_b7.compile(loss = LOSS,\n",
    "                  optimizer = OPTIMIZER,\n",
    "                  metrics = METRICS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986933be",
   "metadata": {},
   "source": [
    "<img src='images/efficientnetb7.png' width='60%'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2405a114",
   "metadata": {},
   "outputs": [],
   "source": [
    "if lu.is_model_already_trained(ef_net_b7):\n",
    "    lu.load_model_training(ef_net_b7)\n",
    "else:               \n",
    "    ef_net_b7.fit(train_data,\n",
    "                  epochs= 5,\n",
    "                  steps_per_epoch = len(train_data),\n",
    "                  validation_data = val_data,\n",
    "                  validation_steps = len(val_data))\n",
    "            \n",
    "    lu.save_model_training(ef_net_b7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc3bd7d",
   "metadata": {},
   "source": [
    "Also trained on 5 epoch, the EfficientNetB7 perform better then the VGG16."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4187b29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lu.plot_model_history(ef_net_b7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b589ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "lu.load_model_training(vgg_16)\n",
    "\n",
    "lu.plot_models_history([vgg_16, ef_net_b7])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa52d232",
   "metadata": {},
   "source": [
    "`ef_net_b7` ends our image classification solution research with an 95.6% accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca98b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "ef_net_b7.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8074e6b7",
   "metadata": {},
   "source": [
    "## Results <a class=\"anchor\" id=\"11\"></a>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc5c816",
   "metadata": {},
   "outputs": [],
   "source": [
    "lu.load_model_training(dnn_1)\n",
    "lu.load_model_training(dnn_2)\n",
    "lu.load_model_training(cnn_1)\n",
    "lu.load_model_training(cnn_2)\n",
    "lu.load_model_training(cnn_3)\n",
    "lu.load_model_training(vgg_16)\n",
    "lu.load_model_training(ef_net_b7)\n",
    "\n",
    "lu.plot_models_history([dnn_1, dnn_2, cnn_1, cnn_2, cnn_3, vgg_16, ef_net_b7])"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1006.10174,
   "end_time": "2022-09-05T05:22:10.027945",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-09-05T05:05:23.926205",
   "version": "2.3.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "427540e104d00e12c644bde433a22f99519267736e4c29c31afd89a435d79c5a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
